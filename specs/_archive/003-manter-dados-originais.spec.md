# Especifica√ß√£o: Preserva√ß√£o de Dados Originais IPT

## Vis√£o Geral

Esta especifica√ß√£o define a implementa√ß√£o da funcionalidade "manter dados originais" no sistema ChatBB, preservando os dados brutos dos IPTs (Integrated Publishing Toolkit) em cole√ß√µes MongoDB separadas, enquanto mant√©m o pipeline de transforma√ß√£o para as cole√ß√µes principais existentes.

## Objetivo

Refatorar os workflows de ingest√£o existentes para implementar um sistema dual de armazenamento que:

1. Preserva dados originais em cole√ß√µes `taxaOriginal` e `ocorrenciasOriginal`
2. Mant√©m o pipeline de transforma√ß√£o existente para as cole√ß√µes principais (`taxa` e `ocorrencias`)
3. Fornece rastreabilidade completa dos dados atrav√©s dos metadados IPT
4. Garante compatibilidade com os workflows GitHub Actions atuais

## Escopo

### Inclu√≠do no Escopo

- Refatora√ß√£o dos scripts de ingest√£o existentes (`fauna.ts`, `flora.ts`, `ocorrencia.ts`)
- Cria√ß√£o de cole√ß√µes MongoDB para dados originais (`taxaOriginal`, `ocorrenciasOriginal`)
- Implementa√ß√£o de rastreabilidade de transforma√ß√µes
- Manuten√ß√£o dos workflows GitHub Actions existentes (sem modifica√ß√£o de estrutura)
- Preserva√ß√£o dos metadados IPT originais com integra√ß√£o ao tipo `DbIpt`

### Fora do Escopo

- Modifica√ß√£o da interface web existente
- Cria√ß√£o de APIs REST adicionais
- Altera√ß√£o da estrutura das cole√ß√µes principais existentes
- Interface de usu√°rio para visualiza√ß√£o dos dados originais
- Modifica√ß√£o dos cronogramas dos workflows (cron schedules)

## Contexto dos Workflows Existentes

### Estrutura Atual dos Workflows

#### Workflow Fauna (update-mongodb-fauna.yml)

- **Cron**: `30 2 * * 0` (Domingos √†s 02:30)
- **Script**: `bun run --filter @darwincore/ingest fauna`
- **Fonte**: DWCA_URL do JBRJ (Jardim Bot√¢nico do Rio de Janeiro)
- **Cole√ß√£o**: `taxa` (kingdom: 'Animalia')

#### Workflow Flora (update-mongodb-flora.yml)

- **Cron**: `0 2 * * 0` (Domingos √†s 02:00)
- **Script**: `bun run --filter @darwincore/ingest flora`
- **Fonte**: DWCA_URL do JBRJ
- **Cole√ß√£o**: `taxa` (kingdom: 'Plantae', 'Fungi')

#### Workflow Ocorr√™ncias (update-mongodb-occurrences.yml)

- **Cron**: `0 3 * * 0` (Domingos √†s 03:00)
- **Script**: `bun run --filter @darwincore/ingest occurrences`
- **Fonte**: M√∫ltiplos IPTs via `referencias/occurrences.csv`
- **Cole√ß√£o**: `ocorrencias`
- **P√≥s-processamento**: Cache clearing (`cache-dashboard`)

### Scripts de Ingest√£o Atuais

#### fauna.ts

- Processa dados DwC-A de fauna (kingdom: 'Animalia')
- Aplica transforma√ß√µes espec√≠ficas (distribution, resourcerelationship, etc.)
- Insere em `taxa` com limpeza por kingdom
- Gerencia versioning via cole√ß√£o `ipts`

#### flora.ts

- Processa dados DwC-A de flora/fungi (kingdom: 'Plantae', 'Fungi')
- Aplica transforma√ß√µes similares √† fauna com diferen√ßas espec√≠ficas
- Insere em `taxa` com limpeza por kingdom
- Gerencia versioning via cole√ß√£o `ipts`

#### ocorrencia.ts

- Processa m√∫ltiplos IPTs via CSV de configura√ß√£o
- Aplica transforma√ß√µes complexas (geospatial, normalization, etc.)
- Insere em `ocorrencias` com verifica√ß√£o de vers√£o individual por IPT
- Gerencia concorr√™ncia e timeouts para m√∫ltiplos servidores IPT

## Requisitos T√©cnicos

### Requisitos Funcionais

#### RF001 - Preserva√ß√£o de Dados Originais

**Descri√ß√£o**: O sistema deve preservar os dados originais de IPTs em cole√ß√µes separadas antes da transforma√ß√£o
**Crit√©rios de Aceita√ß√£o**:

- Dados originais devem ser armazenados nas cole√ß√µes `taxaOriginal` e `ocorrenciasOriginal`
- Estrutura original dos documentos deve ser mantida sem transforma√ß√µes
- Metadados IPT devem ser preservados junto com cada documento

#### RF002 - Rastreabilidade de Transforma√ß√µes

**Descri√ß√£o**: O sistema deve manter rastreabilidade entre dados originais e transformados
**Crit√©rios de Aceita√ß√£o**:

- Cada documento transformado deve referenciar o documento original correspondente
- Metadados de transforma√ß√£o devem incluir timestamp e vers√£o do script
- Pipeline de transforma√ß√£o deve ser documentado no n√≠vel do documento

#### RF003 - Compatibilidade com Workflows Existentes

**Descri√ß√£o**: O sistema deve manter total compatibilidade com os workflows GitHub Actions existentes
**Crit√©rios de Aceita√ß√£o**:

- Scripts existentes devem ser modificados internamente sem alterar interface
- Workflows GitHub Actions devem continuar funcionando sem modifica√ß√µes
- Cronogramas e configura√ß√µes de workflows devem permanecer inalterados
- Performance da ingest√£o n√£o deve ser significativamente impactada

#### RF004 - Integra√ß√£o com Sistema de Versioning

**Descri√ß√£o**: O sistema deve integrar com o sistema de versioning IPT existente
**Crit√©rios de Aceita√ß√£o**:

- Versioning baseado na cole√ß√£o `ipts` deve ser mantido
- Dados originais devem ser versionados junto com dados transformados
- Limpeza de vers√µes antigas deve incluir dados originais

### Requisitos N√£o-Funcionais

#### RNF001 - Performance

- Tempo de ingest√£o n√£o deve aumentar mais que 25%
- √çndices apropriados devem ser criados para consultas eficientes
- Processamento de dados originais deve ser otimizado

#### RNF002 - Armazenamento

- Duplica√ß√£o de dados deve ser gerenciada eficientemente
- Compress√£o MongoDB deve ser utilizada quando apropriada
- √çndices devem ser otimizados para minimizar overhead

#### RNF003 - Integridade

- Dados originais devem ser imut√°veis ap√≥s inser√ß√£o
- Refer√™ncias entre cole√ß√µes devem ser consistentes
- Falhas na preserva√ß√£o original n√£o devem impedir transforma√ß√£o

## Arquitetura de Refatora√ß√£o

### Estrutura de Cole√ß√µes

#### Nova Cole√ß√£o `taxaOriginal`

```typescript
interface TaxaOriginalDocument {
  _id: string // ID gerado pelo MongoDB
  iptId: string // ID do IPT fonte (refer√™ncia para DbIpt)
  originalId: string // ID original do documento no DwC-A
  originalData: any // Dados originais sem transforma√ß√£o
  metadata: {
    ingestedAt: Date // Timestamp de ingest√£o
    iptVersion: string // Vers√£o do IPT (compat√≠vel com DbIpt.version)
    scriptVersion: string // Vers√£o do script de transforma√ß√£o
    kingdom: string // Reino (Animalia/Plantae/Fungi)
    sourceUrl: string // URL fonte do DwC-A
  }
}
```

#### Nova Cole√ß√£o `ocorrenciasOriginal`

```typescript
interface OcorrenciasOriginalDocument {
  _id: string // ID gerado pelo MongoDB
  iptId: string // ID do IPT fonte (refer√™ncia para DbIpt)
  originalId: string // ID original do documento no DwC-A
  originalData: any // Dados originais sem transforma√ß√£o
  metadata: {
    ingestedAt: Date // Timestamp de ingest√£o
    iptVersion: string // Vers√£o do IPT (compat√≠vel com DbIpt.version)
    scriptVersion: string // Vers√£o do script de transforma√ß√£o
    kingdom: string[] // Reinos associados ao IPT
    sourceUrl: string // URL fonte do DwC-A
    tag: string // Tag do IPT fonte
    repositorio: string // Nome do reposit√≥rio
  }
}
```

#### Modifica√ß√µes nas Cole√ß√µes Principais

As cole√ß√µes `taxa` e `ocorrencias` receber√£o novos campos opcionais para rastreabilidade:

```typescript
interface TransformedDocument {
  // ... campos existentes ...
  originalRef?: {
    collectionName: string // "taxaOriginal" ou "ocorrenciasOriginal"
    documentId: string // _id do documento original
    transformedAt: Date // Timestamp da transforma√ß√£o
    scriptVersion: string // Vers√£o do script de transforma√ß√£o
  }
}
```

### Fluxo de Dados Refatorado

```mermaid
graph TD
    A[IPT Source] --> B[Download DwC-A]
    B --> C[Extract Original Data]
    C --> D[Store in Original Collections]
    D --> E[Apply Existing Transformations]
    E --> F[Store in Main Collections with originalRef]
    F --> G[Update IPT Metadata]
    D --> H[Create Indexes]
    F --> H
```

## Implementa√ß√£o

### Abordagem de Refatora√ß√£o

#### Estrat√©gia de Modifica√ß√£o

1. **Preservar interfaces existentes**: Scripts mant√™m mesma assinatura e comportamento externo
2. **Adicionar camadas de preserva√ß√£o**: Inserir l√≥gica de armazenamento original antes da transforma√ß√£o
3. **Manter compatibilidade**: Garantir que falhas na preserva√ß√£o n√£o quebrem o fluxo principal
4. **Otimizar performance**: Implementar armazenamento original de forma eficiente

#### Padr√£o de Implementa√ß√£o

```typescript
// Padr√£o geral para todos os scripts
async function storeOriginalData(data: any[], ipt: Ipt, metadata: any) {
  // L√≥gica para armazenar dados originais
}

async function main() {
  // 1. Download e extra√ß√£o (existente)
  const { json, ipt } = await processaZip(url);

  // 2. NOVO: Armazenar dados originais
  await storeOriginalData(Object.entries(json), ipt, {...});

  // 3. Transforma√ß√£o (existente)
  const transformedData = processaData(json);

  // 4. Armazenamento transformado (modificado para incluir originalRef)
  await storeTransformedData(transformedData, ipt);
}
```

### Fase 1: Refatora√ß√£o do Script fauna.ts

#### 1.1 Fun√ß√µes Adicionais

```typescript
interface OriginalTaxaStorage {
  storeOriginalTaxa(
    entries: [string, any][],
    ipt: Ipt,
    kingdom: string
  ): Promise<Map<string, string>>
  cleanOriginalTaxa(iptId: string): Promise<void>
}
```

#### 1.2 Modifica√ß√µes na Fun√ß√£o Principal

- Adicionar armazenamento original antes da transforma√ß√£o
- Modificar inser√ß√£o em `taxa` para incluir `originalRef`
- Manter l√≥gica de versioning existente

### Fase 2: Refatora√ß√£o do Script flora.ts

#### 2.1 Implementa√ß√£o Similar

- Aplicar mesmo padr√£o do fauna.ts
- Considerar diferen√ßas espec√≠ficas (Plantae + Fungi)
- Manter compatibilidade com transforma√ß√µes existentes

### Fase 3: Refatora√ß√£o do Script ocorrencia.ts

#### 3.1 Desafios Espec√≠ficos

- M√∫ltiplos IPTs processados em batch
- Concorr√™ncia e timeouts
- Diferentes configura√ß√µes por IPT via CSV

#### 3.2 Estrat√©gia de Implementa√ß√£o

- Armazenar originais por IPT individual
- Manter verifica√ß√£o de vers√£o individual
- Implementar limpeza granular por IPT

### Fase 4: Cria√ß√£o de √çndices e Otimiza√ß√µes

#### 4.1 √çndices para Cole√ß√µes Originais

```javascript
// taxaOriginal
db.taxaOriginal.createIndex({ iptId: 1, originalId: 1 }, { unique: true })
db.taxaOriginal.createIndex({ 'metadata.kingdom': 1 })
db.taxaOriginal.createIndex({ 'metadata.ingestedAt': 1 })
db.taxaOriginal.createIndex({ 'metadata.iptVersion': 1 })

// ocorrenciasOriginal
db.ocorrenciasOriginal.createIndex(
  { iptId: 1, originalId: 1 },
  { unique: true }
)
db.ocorrenciasOriginal.createIndex({ 'metadata.kingdom': 1 })
db.ocorrenciasOriginal.createIndex({ 'metadata.ingestedAt': 1 })
db.ocorrenciasOriginal.createIndex({ 'metadata.tag': 1 })
db.ocorrenciasOriginal.createIndex({ 'metadata.repositorio': 1 })
```

#### 4.2 √çndices para Rastreabilidade

```javascript
// taxa
db.taxa.createIndex({ 'originalRef.documentId': 1 }, { sparse: true })

// ocorrencias
db.ocorrencias.createIndex({ 'originalRef.documentId': 1 }, { sparse: true })
```

## Valida√ß√£o e Testes

### Cen√°rios de Teste

#### CT001 - Refatora√ß√£o fauna.ts

1. Executar script fauna.ts com URL existente
2. Verificar armazenamento em `taxaOriginal`
3. Verificar transforma√ß√£o mantida em `taxa`
4. Validar rastreabilidade atrav√©s de `originalRef`
5. Confirmar que workflow GitHub Actions continua funcionando

#### CT002 - Refatora√ß√£o flora.ts

1. Executar script flora.ts
2. Verificar armazenamento em `taxaOriginal` para Plantae/Fungi
3. Verificar compatibilidade com transforma√ß√µes espec√≠ficas de flora
4. Validar integra√ß√£o com workflow existente

#### CT003 - Refatora√ß√£o ocorrencia.ts

1. Executar script ocorrencia.ts com CSV existente
2. Verificar armazenamento em `ocorrenciasOriginal` para m√∫ltiplos IPTs
3. Verificar manuten√ß√£o de concorr√™ncia e timeouts
4. Validar processamento individual por IPT

#### CT004 - Compatibilidade de Workflows

1. Executar workflows GitHub Actions sem modifica√ß√µes
2. Verificar cronogramas mantidos
3. Confirmar que cache clearing continua funcionando
4. Validar self-hosted runners continuam operacionais

### Crit√©rios de Aceita√ß√£o

#### CA001 - Integridade dos Dados Originais

- Todos os dados originais devem ser preservados sem modifica√ß√£o
- N√∫mero de documentos em cole√ß√µes originais deve corresponder aos transformados
- Rastreabilidade deve ser consistente onde implementada

#### CA002 - Compatibilidade Total

- Workflows GitHub Actions devem funcionar sem modifica√ß√µes
- Scripts devem manter mesma interface externa
- Cronogramas e configura√ß√µes devem permanecer inalterados

#### CA003 - Performance Aceit√°vel

- Tempo de ingest√£o n√£o deve exceder 125% do tempo original
- Uso de mem√≥ria deve permanecer dentro de limites aceit√°veis
- Falhas na preserva√ß√£o original n√£o devem quebrar fluxo principal

## Cronograma

### Sprint 1 (Semana 1-2)

- [ ] An√°lise detalhada dos scripts existentes
- [ ] Design da arquitetura de preserva√ß√£o original
- [ ] Implementa√ß√£o da refatora√ß√£o do fauna.ts
- [ ] Testes iniciais de compatibilidade

### Sprint 2 (Semana 3-4)

- [ ] Refatora√ß√£o do flora.ts
- [ ] Refatora√ß√£o do ocorrencia.ts
- [ ] Implementa√ß√£o de √≠ndices otimizados
- [ ] Testes de integra√ß√£o com workflows

### Sprint 3 (Semana 5-6)

- [ ] Testes de performance e otimiza√ß√£o
- [ ] Valida√ß√£o de compatibilidade total
- [ ] Documenta√ß√£o t√©cnica
- [ ] Prepara√ß√£o para deploy

## Riscos e Mitiga√ß√µes

### R001 - Quebra de Compatibilidade

**Risco**: Modifica√ß√µes internas quebram workflows existentes
**Mitiga√ß√£o**: Manter interfaces externas inalteradas e testes extensivos

### R002 - Impact na Performance

**Risco**: Duplica√ß√£o causa degrada√ß√£o significativa
**Mitiga√ß√£o**: Otimiza√ß√£o de √≠ndices e implementa√ß√£o ass√≠ncrona quando poss√≠vel

### R003 - Falhas na Preserva√ß√£o Original

**Risco**: Erros na preserva√ß√£o quebram fluxo principal
**Mitiga√ß√£o**: Implementar preserva√ß√£o como best-effort, sem bloquear transforma√ß√£o

### R004 - Aumento Excessivo de Armazenamento

**Risco**: Duplica√ß√£o dobra uso de storage
**Mitiga√ß√£o**: Monitoramento de uso e implementa√ß√£o de compress√£o

## Conclus√£o

Esta especifica√ß√£o define uma abordagem de refatora√ß√£o conservadora que preserva a funcionalidade existente enquanto adiciona capacidades de preserva√ß√£o de dados originais. A estrat√©gia prioriza compatibilidade total com workflows existentes e minimiza riscos operacionais atrav√©s de modifica√ß√µes internas controladas.

## Execution Flow (main)

```
1. Parse user description from Input
   ‚Üí Feature clearly defined: preserve original data during IPT ingestion
2. Extract key concepts from description
   ‚Üí Actors: data ingestion system, transformation workflows
   ‚Üí Actions: ingest raw data, transform data, maintain parallel collections
   ‚Üí Data: IPT data (fauna, flora, ocorrencias), original and transformed collections
   ‚Üí Constraints: same ID requirement, clear separation of transformation pipeline
3. For each unclear aspect:
   ‚Üí All key aspects are well-defined in the description
4. Fill User Scenarios & Testing section
   ‚Üí Data administrator ingests IPT data and verifies original preservation
5. Generate Functional Requirements
   ‚Üí Each requirement is testable and specific
6. Identify Key Entities
   ‚Üí Collections, documents, transformation workflows
7. Run Review Checklist
   ‚Üí No implementation details, focused on business needs
8. Return: SUCCESS (spec ready for planning)
```

---

## ‚ö° Quick Guidelines

- ‚úÖ Focus on WHAT users need and WHY
- ‚ùå Avoid HOW to implement (no tech stack, APIs, code structure)
- üë• Written for business stakeholders, not developers

---

## Clarifications

### Session 2025-09-29

- Q: Que informa√ß√µes espec√≠ficas devem ser rastreadas entre documentos originais e transformados? ‚Üí A: Apenas refer√™ncia bidirecional por ID
- Q: Como o sistema deve tratar tentativas simult√¢neas de transforma√ß√£o dos mesmos dados originais? ‚Üí A: Cancelar atual; enfileirar pr√≥ximo
- Q: O que o sistema deve fazer quando encontra um documento original com ID duplicado durante nova ingest√£o? ‚Üí A: Sobrescrever dados originais existentes
- Q: Como o sistema deve proceder quando o pipeline de transforma√ß√£o falha parcialmente (alguns documentos processados, outros n√£o)? ‚Üí A: Ignorar falhas ao transformar -> fallback para o valor original na base transformada
- Q: Qual deve ser o n√≠vel de granularidade para tornar o pipeline de transforma√ß√£o "bem destacado e evidente"? ‚Üí A: cada transforma√ß√£o deve ser definida como uma fun√ß√£o de entrada e sa√≠da. O pipeline de transforma√ß√£o deve executrar todas em s√©rie, para cada documento

---

## User Scenarios & Testing _(mandatory)_

### Primary User Story

Como administrador de dados de biodiversidade, eu preciso que todos os dados originais dos IPTs sejam preservados integralmente durante o processo de ingest√£o, para que eu possa rastrear transforma√ß√µes, auditar mudan√ßas, e garantir a integridade cient√≠fica dos dados mesmo ap√≥s processamento.

### Acceptance Scenarios

1. **Given** que novos dados de fauna s√£o recebidos de um IPT, **When** o sistema executa a ingest√£o, **Then** os dados originais devem ser armazenados na cole√ß√£o `taxaOriginal` sem nenhuma transforma√ß√£o
2. **Given** que dados originais foram armazenados, **When** o pipeline de transforma√ß√£o √© executado, **Then** os dados transformados devem ser armazenados na cole√ß√£o principal `taxa` mantendo exatamente o mesmo ID do documento original
3. **Given** que dados de ocorr√™ncias s√£o ingeridos, **When** o processo √© completado, **Then** cada documento original em `occurrenciasOriginal` deve ter um documento correspondente em `ocorrencias` com ID id√™ntico
4. **Given** que um workflow de transforma√ß√£o falha, **When** o administrador reinicia o processo, **Then** o sistema deve poder reprocessar os dados originais sem precisar fazer nova ingest√£o do IPT

### Edge Cases

- **Documentos duplicados**: Quando um documento original j√° existe com o mesmo ID durante uma nova ingest√£o, o sistema deve sobrescrever os dados originais existentes
- **Falhas na transforma√ß√£o**: Quando o pipeline de transforma√ß√£o falha para um documento espec√≠fico, o sistema deve usar fallback copiando o valor original para a base transformada
- O que acontece se um documento original for corrompido mas o transformado ainda existir?

## Requirements _(mandatory)_

### Functional Requirements

- **FR-001**: Sistema DEVE preservar todos os dados originais dos IPTs em cole√ß√µes separadas (`taxaOriginal`, `occurrenciasOriginal`) sem nenhuma modifica√ß√£o
- **FR-002**: Sistema DEVE aplicar transforma√ß√µes apenas nos dados que v√£o para as cole√ß√µes principais (`taxa`, `ocorrencias`)
- **FR-003**: Sistema DEVE garantir que cada documento original tenha exatamente o mesmo ID do documento transformado correspondente
- **FR-004**: Sistema DEVE manter pipeline de transforma√ß√£o onde cada transforma√ß√£o √© definida como fun√ß√£o de entrada e sa√≠da, executadas em s√©rie para cada documento
- **FR-005**: Sistema DEVE permitir workflows independentes de transforma√ß√£o para cada tipo de dados (fauna, flora, ocorrencias) com controle de concorr√™ncia por enfileiramento sequencial
- **FR-006**: Sistema DEVE permitir reprocessamento de transforma√ß√µes a partir dos dados originais sem necessidade de nova ingest√£o
- **FR-007**: Sistema DEVE manter refer√™ncia bidirecional por ID entre documentos originais e transformados
- **FR-008**: Sistema DEVE preservar metadados de origem e timestamp de ingest√£o tanto nos dados originais quanto transformados

### Key Entities _(include if feature involves data)_

- **Cole√ß√£o Original**: Armazena dados IPT sem transforma√ß√£o, mant√©m estrutura exata da fonte
- **Cole√ß√£o Principal**: Armazena dados transformados para uso da aplica√ß√£o, com estrutura padronizada
- **Pipeline de Transforma√ß√£o**: Processo composto por fun√ß√µes sequenciais de entrada e sa√≠da que convertem dados originais em formato padronizado
- **Documento Original**: Registro individual preservado exatamente como recebido do IPT
- **Documento Transformado**: Registro processado e padronizado, vinculado ao original pelo ID
- **Workflow de Tipo**: Processo espec√≠fico de transforma√ß√£o para cada categoria (fauna, flora, ocorrencias)

---

## Review & Acceptance Checklist

_GATE: Automated checks run during main() execution_

### Content Quality

- [x] No implementation details (languages, frameworks, APIs)
- [x] Focused on user value and business needs
- [x] Written for non-technical stakeholders
- [x] All mandatory sections completed

### Requirement Completeness

- [x] No [NEEDS CLARIFICATION] markers remain
- [x] Requirements are testable and unambiguous
- [x] Success criteria are measurable
- [x] Scope is clearly bounded
- [x] Dependencies and assumptions identified

---

## Execution Status

_Updated by main() during processing_

- [x] User description parsed
- [x] Key concepts extracted
- [x] Ambiguities marked
- [x] User scenarios defined
- [x] Requirements generated
- [x] Entities identified
- [x] Review checklist passed

---
