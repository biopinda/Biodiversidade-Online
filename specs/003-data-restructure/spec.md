# Feature Specification: Reestrutura√ß√£o de Dados - Separa√ß√£o de Ingest√£o e Transforma√ß√£o

**Feature Branch**: `003-data-restructure`  
**Created**: 2025-10-29  
**Status**: Draft  
**Input**: User description: "reestrutura√ß√£o de dados. Leia o https://github.com/biopinda/Biodiversidade-Online/blob/main/PRD.md para as especifica√ß√µes"

## Clarifications

### Session 2025-10-29

- Q: What is the data retention policy for raw IPT collections (`taxa_ipt` and `occurrences_ipt`)? ‚Üí A: Retain indefinitely until manual deletion is triggered for audit/reproducibility purposes
- Q: Which concurrency control mechanism should be implemented to prevent race conditions during transformation processes? ‚Üí A: Process-level flag in MongoDB collection (e.g., `transform_status` collection with timestamps)
- Q: What happens when the external collector parsing algorithm dependency (`https://github.com/biopinda/coletores-BO`) is unavailable? ‚Üí A: Parse fails gracefully, preserve original `recordedBy` unchanged, log warning
- Q: What metrics/monitoring targets should be implemented for operational health and observability? ‚Üí A: Basic operational metrics (ingestion/transformation duration, record counts, error rates)
- Q: Should transformation processes be triggered manually or automatically after ingestion completes? ‚Üí A: Automatic transformation triggered immediately after each successful ingestion via GitHub workflows, with workflow_dispatch option for manual triggering

### Session 2025-10-31

- Q: Should transformation be a separate step after ingestion or integrated into ingestion? ‚Üí A: Integrated into ingestion - transform immediately after inserting raw data using upsert to both raw and transformed collections
- Q: How should we handle shared code between ingest and transform packages to avoid cyclic dependencies? ‚Üí A: Create `packages/shared` for utilities like deterministic-id, database connections, collection names, and metrics
- Q: When should bulk re-transformation be triggered? ‚Üí A: Only when packages/transform version is bumped (indicating transformation logic changed) or via manual workflow_dispatch
- Q: Should ingestion workflows chain to transformation workflows? ‚Üí A: No - ingestion scripts import and call transformation functions directly; separate transform workflows only for bulk re-processing

## User Scenarios & Testing _(mandatory)_

### User Story 1 - Ingest√£o e Transforma√ß√£o Autom√°tica de Dados de Taxa (Priority: P1) üéØ MVP

O sistema deve baixar e processar automaticamente os dados taxon√¥micos da Flora e Fauna do Brasil diretamente dos reposit√≥rios IPT oficiais, armazenando os dados brutos em `taxa_ipt` e imediatamente transformando-os para `taxa` no MongoDB. Esta √© a base fundamental do sistema - em uma √∫nica opera√ß√£o, temos dados brutos para auditoria e dados transformados para uso.

**Why this priority**: Esta hist√≥ria representa a funda√ß√£o do sistema de dados. Todos os demais processos (API, interface) dependem da disponibilidade dos dados transformados. Ao integrar ingest√£o e transforma√ß√£o em um √∫nico passo, garantimos consist√™ncia e simplificamos o pipeline.

**Independent Test**: Pode ser totalmente testado executando o comando de ingest√£o de taxa e verificando se: (1) os arquivos DwC-A s√£o baixados dos URLs corretos, (2) os registros s√£o inseridos na cole√ß√£o `taxa_ipt` com estrutura JSON conforme schema, (3) registros transformados s√£o inseridos em `taxa` com mesmo `_id`, (4) transforma√ß√µes aplicadas corretamente (canonicalName, filtros, enriquecimentos).

**Acceptance Scenarios**:

1. **Given** que o reposit√≥rio IPT da Fauna est√° dispon√≠vel, **When** o sistema executa `bun run ingest:fauna`, **Then** todos os registros de esp√©cies da fauna s√£o: (a) inseridos em `taxa_ipt` com campos DwC originais preservados, (b) transformados e inseridos em `taxa` com canonicalName, filtros e enriquecimentos aplicados, (c) ambos registros possuem `_id` id√™ntico baseado em `taxonID`
2. **Given** que o reposit√≥rio IPT da Flora est√° dispon√≠vel, **When** o sistema executa `bun run ingest:flora`, **Then** todos os registros s√£o processados em duas etapas: raw insert em `taxa_ipt` seguido de transform e upsert em `taxa`
3. **Given** que j√° existem registros em `taxa_ipt` e `taxa`, **When** uma nova ingest√£o √© executada, **Then** registros duplicados s√£o identificados pelo `_id` (taxonID) e atualizados (upsert) em ambas cole√ß√µes sem criar duplicatas
4. **Given** que o download do arquivo DwC-A falha, **When** o sistema tenta acessar o IPT, **Then** uma mensagem de erro clara √© exibida e o processo pode ser retomado posteriormente (nenhum registro √© inserido em nenhuma cole√ß√£o)
5. **Given** que um registro √© inserido em `taxa_ipt`, **When** a transforma√ß√£o autom√°tica falha, **Then** o erro √© registrado mas o registro bruto permanece em `taxa_ipt` para auditoria
6. **Given** que a transforma√ß√£o processa um registro, **When** cria o documento em `taxa`, **Then** o campo `canonicalName` √© gerado corretamente a partir de `scientificName`, dados de amea√ßa/invasoras/UCs s√£o agregados quando aplic√°vel
7. **Given** que um registro possui `taxonRank` = "GENERO", **When** a transforma√ß√£o autom√°tica √© executada, **Then** o registro aparece em `taxa_ipt` mas N√ÉO em `taxa` (filtrado durante transforma√ß√£o)

---

### User Story 2 - Ingest√£o e Transforma√ß√£o Autom√°tica de Dados de Ocorr√™ncias (Priority: P1)

O sistema deve processar todos os recursos DwC-A listados no arquivo `occurrences.csv`, armazenando os dados brutos em `occurrences_ipt` e imediatamente transformando-os para `occurrences` no MongoDB. Juntamente com a User Story 1, esta hist√≥ria completa o pipeline integrado de dados.

**Why this priority**: Dados de ocorr√™ncias s√£o essenciais para mapas, visualiza√ß√µes geogr√°ficas e an√°lises de distribui√ß√£o de esp√©cies. Esta hist√≥ria e a User Story 1 formam o MVP completo - ambas devem funcionar para termos dados brutos audit√°veis e dados transformados prontos para uso.

**Independent Test**: Pode ser totalmente testado executando o comando de ingest√£o de ocorr√™ncias e verificando se: (1) todos os 507 recursos listados em `occurrences.csv` s√£o processados, (2) os registros s√£o inseridos em `occurrences_ipt` e `occurrences` conforme schemas, (3) transforma√ß√µes s√£o aplicadas (geoPoint, normaliza√ß√£o de datas/estados, vincula√ß√£o taxon√¥mica), (4) `_id` √© preservado entre cole√ß√µes.

**Acceptance Scenarios**:

1. **Given** que o arquivo `occurrences.csv` cont√©m 507 recursos IPT, **When** o sistema executa `bun run ingest:occurrences`, **Then** todos os recursos s√£o processados: (a) dados brutos inseridos em `occurrences_ipt`, (b) dados transformados inseridos em `occurrences` com valida√ß√µes geogr√°ficas e enriquecimentos aplicados
2. **Given** que um recurso IPT est√° temporariamente indispon√≠vel, **When** o sistema tenta baix√°-lo, **Then** o erro √© registrado e o processo continua com os pr√≥ximos recursos sem interromper toda a ingest√£o
3. **Given** que registros de ocorr√™ncias j√° existem, **When** uma nova ingest√£o √© executada, **Then** registros s√£o atualizados (upsert) em `occurrences_ipt` e `occurrences` usando `_id` como chave √∫nica
4. **Given** que um arquivo DwC-A √© processado, **When** a transforma√ß√£o autom√°tica cria registros em `occurrences`, **Then** campo `geoPoint` √© criado quando coordenadas s√£o v√°lidas, datas s√£o parseadas para day/month/year, estados s√£o normalizados
5. **Given** que duas ocorr√™ncias do mesmo IPT possuem `occurrenceID` id√™ntico, **When** s√£o processadas, **Then** o segundo registro sobrescreve o primeiro (upsert) em ambas cole√ß√µes garantindo unicidade de \_id
6. **Given** que uma ocorr√™ncia possui `scientificName` que √© sin√¥nimo, **When** a transforma√ß√£o autom√°tica √© executada, **Then** o nome √© validado contra `taxa` e substitu√≠do pelo nome aceito com `taxonID` correto
7. **Given** que uma ocorr√™ncia possui `country` diferente de "Brasil", **When** a transforma√ß√£o autom√°tica √© executada, **Then** o registro aparece em `occurrences_ipt` mas N√ÉO em `occurrences` (filtrado durante transforma√ß√£o)

---

### User Story 3 - Re-transforma√ß√£o em Massa de Dados (Priority: P2)

O sistema deve permitir re-executar o processo de transforma√ß√£o sobre todos os dados brutos existentes em `taxa_ipt` e `occurrences_ipt`, regenerando as cole√ß√µes `taxa` e `occurrences`. Esta funcionalidade √© essencial quando a l√≥gica de transforma√ß√£o √© atualizada.

**Why this priority**: Re-transforma√ß√£o √© necess√°ria apenas quando a l√≥gica de transforma√ß√£o muda (novo campo, filtro atualizado, corre√ß√£o de bug). Como ingest√£o j√° transforma automaticamente, esta hist√≥ria √© secund√°ria mas importante para manuten√ß√£o.

**Independent Test**: Pode ser totalmente testado: (1) modificando um arquivo em `packages/transform/src`, (2) incrementando a vers√£o em `packages/transform/package.json`, (3) executando `bun run transform:taxa` ou `bun run transform:occurrences`, (4) verificando que todos os registros em `taxa_ipt`/`occurrences_ipt` foram reprocessados e atualizados em `taxa`/`occurrences`.

**Acceptance Scenarios**:

1. **Given** que a vers√£o de `@darwincore/transform` foi incrementada de 1.0.0 para 1.1.0, **When** o workflow GitHub Actions detecta mudan√ßa no package.json, **Then** o workflow de re-transforma√ß√£o √© disparado automaticamente
2. **Given** que existem 100.000 registros em `taxa_ipt`, **When** o comando `bun run transform:taxa` √© executado, **Then** todos os registros s√£o reprocessados em lotes, transformados e atualizados em `taxa` preservando `_id`
3. **Given** que a transforma√ß√£o de ocorr√™ncias est√° em execu√ß√£o, **When** outro processo tenta iniciar transforma√ß√£o, **Then** o sistema detecta lock em `transform_status` e aborta com mensagem clara
4. **Given** que um usu√°rio executa manualmente `workflow_dispatch` para transform-taxa, **When** o workflow √© disparado, **Then** a re-transforma√ß√£o completa √© executada independente da vers√£o do pacote
5. **Given** que a l√≥gica de transforma√ß√£o falha em 10% dos registros, **When** a re-transforma√ß√£o √© executada, **Then** os 90% restantes s√£o processados com sucesso, erros s√£o registrados em m√©tricas, e registros com erro preservam vers√£o anterior ou s√£o marcados para revis√£o

---

### User Story 4 - Exposi√ß√£o de APIs RESTful (Priority: P3)

O sistema deve expor endpoints de API documentados via Swagger para permitir consultas program√°ticas aos dados transformados de taxa e ocorr√™ncias. Esta hist√≥ria permite que sistemas externos e a interface web consumam os dados de forma estruturada.

**Why this priority**: APIs s√£o o mecanismo de acesso aos dados transformados. Sem elas, os dados existem mas n√£o s√£o acess√≠veis. Depende das stories anteriores (precisa de dados transformados para expor).

**Independent Test**: Pode ser totalmente testado acessando a documenta√ß√£o Swagger e executando requests para: (1) consultar taxa por nome cient√≠fico, (2) buscar ocorr√™ncias por coordenadas geogr√°ficas, (3) filtrar dados por m√∫ltiplos crit√©rios, (4) obter estat√≠sticas agregadas.

**Acceptance Scenarios**:

1. **Given** que a API est√° dispon√≠vel, **When** um usu√°rio acessa `/api/docs`, **Then** a documenta√ß√£o Swagger completa √© exibida com todos os endpoints dispon√≠veis
2. **Given** que existem registros em `taxa`, **When** uma requisi√ß√£o GET √© feita para `/api/taxa?scientificName=Panthera onca`, **Then** a API retorna os dados do taxon em formato JSON
3. **Given** que existem registros em `occurrences`, **When** uma requisi√ß√£o GET √© feita para `/api/occurrences?stateProvince=S√£o Paulo&limit=100`, **Then** a API retorna at√© 100 ocorr√™ncias do estado especificado
4. **Given** que um filtro geogr√°fico √© aplicado, **When** uma requisi√ß√£o GET √© feita para `/api/occurrences?bbox=-46.5,-23.7,-46.3,-23.5`, **Then** apenas ocorr√™ncias dentro do bounding box s√£o retornadas
5. **Given** que m√∫ltiplos filtros s√£o combinados, **When** uma requisi√ß√£o complexa √© feita, **Then** a API aplica todos os filtros corretamente e retorna resultados paginados

---

### User Story 5 - Adapta√ß√£o da Interface Web (Priority: P3)

As p√°ginas web existentes (chat, taxa search, dashboard, map, tree view) devem ser adaptadas para consumir dados das novas cole√ß√µes `taxa` e `occurrences` atrav√©s das APIs, mantendo todas as funcionalidades atuais. Esta hist√≥ria garante que usu√°rios finais continuem acessando os dados atrav√©s das interfaces existentes.

**Why this priority**: A interface web √© a camada de apresenta√ß√£o para usu√°rios finais. Sua adapta√ß√£o √© importante mas pode ser feita depois que APIs estejam dispon√≠veis. Depende da User Story 4 (precisa de APIs funcionando).

**Independent Test**: Pode ser totalmente testado navegando em cada p√°gina web e verificando se: (1) http://localhost:4321/taxa retorna resultados de busca, (2) http://localhost:4321/mapa exibe ocorr√™ncias georreferenciadas, (3) http://localhost:4321/dashboard mostra estat√≠sticas atualizadas, (4) http://localhost:4321/tree exibe a √°rvore taxon√¥mica.

**Acceptance Scenarios**:

1. **Given** que a p√°gina de busca de taxa est√° carregada, **When** um usu√°rio pesquisa por "Panthera onca", **Then** os resultados s√£o carregados da cole√ß√£o `taxa` via API
2. **Given** que o mapa de ocorr√™ncias est√° carregado, **When** um usu√°rio aplica filtros, **Then** os dados s√£o buscados da cole√ß√£o `occurrences` e os pontos s√£o renderizados corretamente
3. **Given** que o dashboard est√° carregado, **When** as estat√≠sticas s√£o calculadas, **Then** os dados v√™m das cole√ß√µes `taxa` e `occurrences` via cache ou API
4. **Given** que a √°rvore taxon√¥mica est√° carregada, **When** um usu√°rio expande um n√≥, **Then** os dados hier√°rquicos s√£o carregados da cole√ß√£o `taxa`
5. **Given** que a interface de chat est√° carregada, **When** um usu√°rio faz uma pergunta sobre biodiversidade, **Then** o ChatBB consulta as novas cole√ß√µes para fornecer respostas

---

### Edge Cases

- **Falha de conex√£o IPT durante ingest√£o**: Quando um recurso IPT est√° indispon√≠vel temporariamente, o sistema registra o erro, pula para o pr√≥ximo recurso e permite reprocessamento posterior apenas dos recursos falhados
- **Registros com campos obrigat√≥rios ausentes**: Quando um registro DwC-A n√£o possui campos obrigat√≥rios do schema (e.g., `occurrenceID` ausente), o sistema registra warning detalhado mas continua processamento dos demais registros
- **TaxonID ausente ou inv√°lido**: Quando um registro de taxa n√£o possui `taxonID` v√°lido, o sistema gera `_id` alternativo usando hash de `scientificName` + `kingdom` para garantir unicidade e consist√™ncia
- **OccurrenceID duplicado entre IPTs**: Quando dois IPTs diferentes possuem registros com mesmo `occurrenceID`, o sistema gera `_id` √∫nico combinando `occurrenceID` + `iptId` (hash ou concatena√ß√£o) para evitar colis√£o
- **OccurrenceID ausente**: Quando um registro de ocorr√™ncia n√£o possui `occurrenceID`, o sistema gera `_id` usando hash de campos-chave (catalogNumber, recordNumber, eventDate, locality, recordedBy) garantindo rastreabilidade
- **Sincroniza√ß√£o de \_id entre cole√ß√µes**: Quando a transforma√ß√£o √© executada, o sistema SEMPRE copia `_id` de raw para transformed sem modifica√ß√£o, garantindo rastreabilidade perfeita
- **Verifica√ß√£o de integridade de \_id**: Quando transforma√ß√£o completa, o sistema valida que para cada `_id` em `taxa` existe exatamente um documento com mesmo `_id` em `taxa_ipt` (e vice-versa para occurrences)
- **Sin√¥nimos n√£o encontrados em taxa**: Quando uma ocorr√™ncia referencia um `scientificName` que √© sin√¥nimo mas n√£o est√° na cole√ß√£o `taxa`, o sistema mant√©m o nome original e adiciona flag de valida√ß√£o pendente
- **Coordenadas geogr√°ficas inv√°lidas**: Quando `decimalLatitude` ou `decimalLongitude` est√£o fora dos ranges v√°lidos (-90 a 90, -180 a 180), o sistema registra o erro mas preserva os valores originais em campo separado para auditoria
- **M√∫ltiplas execu√ß√µes de transforma√ß√£o**: Quando a transforma√ß√£o √© executada m√∫ltiplas vezes sobre os mesmos dados brutos, o sistema usa upsert por `_id` para evitar duplicatas, garantindo idempot√™ncia
- **Mudan√ßas no schema IPT**: Quando o formato do arquivo DwC-A do IPT muda (novos campos ou estrutura alterada), o sistema registra campos desconhecidos sem falhar, permitindo ajustes posteriores no c√≥digo
- **Volume massivo de dados**: Quando milh√µes de registros s√£o processados, o sistema usa processamento em lotes (batch) com commit peri√≥dico para evitar timeouts de conex√£o e permitir recupera√ß√£o de falhas parciais
- **Arquivos DwC-A corrompidos**: Quando um arquivo ZIP baixado est√° corrompido ou incompleto, o sistema detecta a corrup√ß√£o antes de processar, registra erro e mant√©m vers√£o anterior dos dados se dispon√≠vel
- **Concorr√™ncia em transforma√ß√µes**: Quando m√∫ltiplos processos de transforma√ß√£o tentam executar simultaneamente, o sistema usa cole√ß√£o MongoDB `transform_status` com flags de processo e timestamps at√¥micos para evitar condi√ß√µes de corrida (permite detec√ß√£o de locks obsoletos via timeout)
- **Perda de refer√™ncias entre cole√ß√µes**: Quando registros em `taxa_ipt` s√£o deletados ap√≥s a cria√ß√£o de `occurrences`, o sistema mant√©m integridade referencial atrav√©s de valida√ß√µes que identificam ocorr√™ncias √≥rf√£s
- **Depend√™ncia externa indispon√≠vel**: Quando o reposit√≥rio de parsing de coletores (`https://github.com/biopinda/coletores-BO`) est√° inacess√≠vel ou retorna erro, o sistema preserva o campo `recordedBy` original sem parsing, registra warning, e continua processamento normalmente

## Requirements _(mandatory)_

### Functional Requirements

**Ingest√£o e Transforma√ß√£o Integrada de Dados:**

- **FR-001**: Sistema DEVE baixar automaticamente arquivos DwC-A dos URLs dos reposit√≥rios IPT especificados
- **FR-002**: Sistema DEVE processar arquivos DwC-A da Fauna do Brasil do IPT JBRJ (`https://ipt.jbrj.gov.br/jbrj/archive.do?r=catalogo_taxonomico_da_fauna_do_brasil`)
- **FR-003**: Sistema DEVE processar arquivos DwC-A da Flora e Funga do Brasil do IPT JBRJ (`https://ipt.jbrj.gov.br/jbrj/archive.do?r=lista_especies_flora_brasil`)
- **FR-004**: Sistema DEVE processar todos os 507 recursos DwC-A listados no arquivo `packages/ingest/referencias/occurrences.csv`
- **FR-005**: Sistema DEVE armazenar dados taxon√¥micos brutos na cole√ß√£o MongoDB `taxa_ipt` seguindo o schema `docs/schema-dwc2json-taxa-mongoDBJSON.json`
- **FR-006**: Sistema DEVE armazenar dados de ocorr√™ncias brutas na cole√ß√£o MongoDB `occurrences_ipt` seguindo o schema `docs/schema-dwc2json-ocorrencias-mongoDBJSON.json`
- **FR-007**: Sistema DEVE preservar TODOS os campos DwC originais sem modifica√ß√µes durante a ingest√£o em cole√ß√µes `*_ipt`
- **FR-008**: Sistema DEVE converter estrutura relacional DwC-A para estrutura de documento JSON MongoDB
- **FR-009**: Sistema DEVE gerar `_id` determin√≠stico baseado em chave natural (taxonID para taxa, occurrenceID para ocorr√™ncias) durante ingest√£o para garantir rastreabilidade entre cole√ß√µes raw e transformadas
- **FR-009a**: Para taxa, Sistema DEVE usar `taxonID` do DwC-A como `_id` em `taxa_ipt` (garantindo unicidade e rastreabilidade)
- **FR-009b**: Para ocorr√™ncias, Sistema DEVE gerar `_id` combinando `occurrenceID` + `iptId` (hash ou concatena√ß√£o) para garantir unicidade entre diferentes IPTs
- **FR-009c**: Sistema DEVE reter dados brutos em `taxa_ipt` e `occurrences_ipt` indefinidamente at√© que dele√ß√£o manual seja explicitamente acionada, para fins de auditoria, reprodutibilidade e rastreabilidade de dados
- **FR-010**: Sistema DEVE executar transforma√ß√£o imediatamente ap√≥s inserir cada registro bruto, no mesmo processo de ingest√£o
- **FR-010a**: Scripts de ingest√£o (flora.ts, fauna.ts, ocorrencia.ts) DEVEM importar fun√ß√µes de transforma√ß√£o de `@darwincore/transform`
- **FR-010b**: Sistema DEVE realizar upsert em ambas cole√ß√µes raw e transformed usando mesmo `_id` para manter rastreabilidade
- **FR-010c**: Se transforma√ß√£o falhar para um registro espec√≠fico, Sistema DEVE registrar erro mas continuar processamento, mantendo registro bruto em cole√ß√£o `*_ipt`

**Transforma√ß√£o de Dados Taxon√¥micos:**

- **FR-011**: Sistema DEVE criar registro na cole√ß√£o `taxa` para cada registro em `taxa_ipt` preservando EXATAMENTE o mesmo `_id` (rastreabilidade 1:1)
- **FR-012**: Sistema DEVE filtrar apenas registros com `taxonRank` em ['ESPECIE', 'VARIEDADE', 'FORMA', 'SUB_ESPECIE']
- **FR-013**: Sistema DEVE criar campo `canonicalName` concatenando campos: `genus`, `genericName`, `subgenus`, `infragenericEpithet`, `specificEpithet`, `infraspecificEpithet`, `cultivarEpiteth` (filtrados por Boolean e unidos com espa√ßo)
- **FR-014**: Sistema DEVE criar campo `flatScientificName` removendo caracteres n√£o alfanum√©ricos de `scientificName` e convertendo para lowercase
- **FR-015**: Sistema DEVE processar campo `higherClassification` usando apenas o segundo componente da string separada por ponto-e-v√≠rgula (issue #13)
- **FR-016**: Sistema DEVE normalizar `vernacularname` array: converter `vernacularName` para lowercase com h√≠fens no lugar de espa√ßos, e capitalizar primeira letra de `language`
- **FR-017**: Para Flora/Fungi, Sistema DEVE transformar array `distribution` em objeto estruturado com: `origin` (estabelecimentoMeans do primeiro elemento), `Endemism` (occurrenceRemarks.endemism), `phytogeographicDomains`, `occurrence` (array de locationID ordenado), `vegetationType` (do speciesprofile[0].lifeForm.vegetationType)
- **FR-018**: Para Fauna, Sistema DEVE transformar array `distribution` em objeto estruturado com: `origin`, `occurrence` (locality split por ';'), `countryCode` (split por ';')
- **FR-019**: Sistema DEVE processar `resourcerelationship` array criando campo `othernames` com mapeamento de: `taxonID` (relatedResourceID), `scientificName` (buscado no dwcJson), `taxonomicStatus` (relationshipOfResource), e deletar campo original `resourcerelationship`
- **FR-020**: Para Flora/Fungi, Sistema DEVE transformar `speciesprofile` array pegando primeiro elemento e removendo `vegetationType` de `lifeForm`
- **FR-021**: Sistema DEVE definir `kingdom` = 'Animalia' para registros de Fauna durante transforma√ß√£o
- **FR-022**: Sistema DEVE agregar dados de amea√ßa das cole√ß√µes `cncfloraFungi`, `cncfloraPlantae` e `faunaAmeacada`
- **FR-023**: Sistema DEVE agregar dados de esp√©cies invasoras da cole√ß√£o `invasoras`
- **FR-024**: Sistema DEVE agregar dados de presen√ßa em Unidades de Conserva√ß√£o do arquivo DwC-A `https://ipt.jbrj.gov.br/jbrj/archive.do?r=catalogoucs`

**Transforma√ß√£o de Dados de Ocorr√™ncias:**

- **FR-025**: Sistema DEVE criar registro na cole√ß√£o `occurrences` para cada registro em `occurrences_ipt` preservando EXATAMENTE o mesmo `_id` (rastreabilidade 1:1)
- **FR-026**: Sistema DEVE criar campo `geoPoint` (tipo Point com coordinates [longitude, latitude]) quando `decimalLatitude` e `decimalLongitude` s√£o v√°lidos (num√©ricos e dentro dos ranges -90 a 90 e -180 a 180)
- **FR-027**: Sistema DEVE criar campo `canonicalName` concatenando campos: `genus`, `genericName`, `subgenus`, `infragenericEpithet`, `specificEpithet`, `infraspecificEpithet`, `cultivarEpiteth` (filtrados por Boolean e unidos com espa√ßo)
- **FR-028**: Sistema DEVE criar campo `iptKingdoms` como array resultado do split de `kingdom` do CSV por v√≠rgula ou v√≠rgula-espa√ßo
- **FR-029**: Sistema DEVE criar campo `flatScientificName` removendo caracteres n√£o alfanum√©ricos de `scientificName` (ou canonicalName se scientificName ausente) e convertendo para lowercase
- **FR-030**: Sistema DEVE converter campos `year`, `month`, `day` de string para number quando v√°lidos: year > 0, month entre 1-12, day entre 1-31 (mant√©m como string se inv√°lido para compatibilidade)
- **FR-031**: Sistema DEVE normalizar campo `country` usando mapeamento de normalizeCountryName (Brasil, Brazil ‚Üí Brasil) preservando varia√ß√µes
- **FR-032**: Sistema DEVE normalizar campo `stateProvince` usando mapeamento de normalizeStateName (abrevia√ß√µes e varia√ß√µes ‚Üí nome completo oficial)
- **FR-033**: Sistema DEVE parsear `eventDate` quando √© string: criar objeto Date v√°lido, extrair year/month/day se ausentes ou inv√°lidos, e converter para timestamp (mant√©m string original se parsing falhar)
- **FR-034**: Sistema DEVE adicionar campos `iptId` (ipt.id), `ipt` (reposit√≥rio), `canonicalName`, `iptKingdoms`, `flatScientificName` a todos os registros
- **FR-035**: Sistema DEVE validar `scientificName` contra cole√ß√£o `taxa` e substituir sin√¥nimos por nomes aceitos
- **FR-036**: Sistema DEVE associar `taxonID` correto de `taxa` para cada ocorr√™ncia
- **FR-037**: Sistema DEVE buscar e validar `canonicalName` na cole√ß√£o `taxa`
- **FR-038**: Sistema DEVE harmonizar campo `continent` para valor padronizado "Am√©rica do Sul"
- **FR-039**: Sistema DEVE filtrar e N√ÉO ingerir registros com `country` diferente de "Brasil" (e varia√ß√µes) com alta certeza
- **FR-040**: Sistema DEVE harmonizar campo `county` usando lista oficial de munic√≠pios do IBGE
- **FR-041**: Sistema DEVE criar campo `reproductiveCondition` = "flor" para registros Plantae quando `occurrenceRemarks` cont√©m regex `(^|[\s\p{P}])(fl√¥r|flor)([\s\p{P}]|$)`
- **FR-042**: Sistema DEVE aplicar algoritmo de parsing de coletores do reposit√≥rio `https://github.com/biopinda/coletores-BO` ao campo `recordedBy`
- **FR-042a**: Sistema DEVE preservar campo `recordedBy` original sem modifica√ß√£o quando algoritmo de parsing de coletores falha (reposit√≥rio indispon√≠vel, erro de parsing), registrando warning em log para rastreabilidade

**Re-transforma√ß√£o em Massa:**

- **FR-043**: Sistema DEVE permitir re-executar transforma√ß√£o sobre todos dados brutos via comando CLI `bun run transform:taxa` e `bun run transform:occurrences`
- **FR-044**: Sistema DEVE detectar mudan√ßas de vers√£o em `packages/transform/package.json` e disparar re-transforma√ß√£o via GitHub Actions
- **FR-045**: Sistema DEVE suportar execu√ß√£o manual de re-transforma√ß√£o via `workflow_dispatch` no GitHub Actions
- **FR-046**: Sistema DEVE processar re-transforma√ß√£o em lotes (batch) para evitar timeouts em grandes volumes
- **FR-047**: Sistema DEVE usar cole√ß√£o MongoDB `transform_status` com opera√ß√µes at√¥micas para controlar concorr√™ncia, incluindo campos: process_type (taxa/occurrences), status (running/completed/failed), started_at, updated_at, process_id
- **FR-048**: Sistema DEVE registrar m√©tricas de re-transforma√ß√£o na cole√ß√£o `process_metrics` (dura√ß√£o, contagem de registros, taxa de erro)
- **FR-049**: Sistema DEVE garantir que transforma√ß√£o √© idempotente (m√∫ltiplas execu√ß√µes produzem mesmo resultado)

**Exposi√ß√£o de APIs:**

- **FR-050**: Sistema DEVE expor APIs RESTful usando plataforma Swagger para documenta√ß√£o interativa
- **FR-051**: APIs DEVEM permitir consultas √† cole√ß√£o `taxa` com filtros por campos taxon√¥micos
- **FR-052**: APIs DEVEM permitir consultas √† cole√ß√£o `occurrences` com filtros geogr√°ficos e temporais
- **FR-053**: APIs DEVEM suportar pagina√ß√£o de resultados
- **FR-054**: APIs DEVEM retornar dados em formato JSON
- **FR-055**: APIs DEVEM suportar filtros combinados (m√∫ltiplos par√¢metros simultaneamente)
- **FR-056**: APIs DEVEM incluir metadados de pagina√ß√£o (total de registros, p√°gina atual, total de p√°ginas)

**Adapta√ß√£o de Interface Web:**

- **FR-057**: Interface web DEVE consumir dados das cole√ß√µes `taxa` e `occurrences` atrav√©s das APIs expostas
- **FR-058**: P√°gina de busca de taxa (`/taxa`) DEVE buscar dados da cole√ß√£o `taxa` via API
- **FR-059**: P√°gina de mapa (`/mapa`) DEVE carregar ocorr√™ncias georreferenciadas da cole√ß√£o `occurrences` via API
- **FR-060**: P√°gina de dashboard (`/dashboard`) DEVE calcular estat√≠sticas usando dados das cole√ß√µes `taxa` e `occurrences`
- **FR-061**: P√°gina de √°rvore taxon√¥mica (`/tree`) DEVE construir hierarquia a partir da cole√ß√£o `taxa`
- **FR-062**: Interface de chat (`/chat`) DEVE consultar cole√ß√µes `taxa` e `occurrences` para responder perguntas sobre biodiversidade

**Requisitos T√©cnicos e de Arquitetura:**

- **FR-063**: C√≥digo compartilhado entre pacotes DEVE estar organizado em `packages/shared` (deterministic-id, database connection, collection names, metrics)
- **FR-064**: Rotinas de ingest√£o DEVEM estar organizadas no pacote `packages/ingest` e DEVEM importar transforma√ß√µes de `packages/transform`
- **FR-065**: Rotinas de transforma√ß√£o (re-processamento em massa) DEVEM estar organizadas no pacote `packages/transform`
- **FR-066**: Interface web DEVE permanecer no pacote `packages/web`
- **FR-067**: Sistema DEVE reutilizar c√≥digo existente de fun√ß√µes e rotinas sempre que poss√≠vel (especialmente processaZip, processaEml, normaliza√ß√£o)
- **FR-068**: Sistema DEVE manter plataforma tecnol√≥gica atual (Bun, Astro.js, TypeScript, MongoDB)
- **FR-069**: Sistema DEVE usar Docker com vari√°veis de ambiente para strings de conex√£o e chaves sens√≠veis
- **FR-070**: Sistema DEVE suportar integra√ß√£o opcional com Meilisearch quando necess√°rio
- **FR-071**: Nenhuma informa√ß√£o sens√≠vel DEVE estar exposta no reposit√≥rio p√∫blico
- **FR-072**: Workflows GitHub Actions de ingest√£o N√ÉO DEVEM chamar workflows de transforma√ß√£o (transforma√ß√£o integrada no processo de ingest√£o)
- **FR-073**: Workflows GitHub Actions de transforma√ß√£o DEVEM ser disparados apenas por: (a) mudan√ßa de vers√£o em `packages/transform/package.json`, (b) workflow_dispatch manual

**Requisitos de Processamento em Lote e Resili√™ncia (j√° implementados):**

- **FR-064**: Sistema DEVE processar inser√ß√µes em lotes usando safeInsertMany com chunking autom√°tico quando BSON excede 16MB
- **FR-065**: Sistema DEVE detectar erros de rede (timeout, Connection, ECONNRESET, ENOTFOUND, ECONNREFUSED, AbortError) e marcar IPT servers como offline
- **FR-066**: Sistema DEVE executar version check de IPTs com concorr√™ncia limitada (max 10 simult√¢neos) e timeout de 10 segundos
- **FR-067**: Sistema DEVE usar ordered:false em insertMany para permitir inser√ß√£o parcial em caso de duplicatas
- **FR-068**: Sistema DEVE tratar recursos 404 (n√£o encontrados) sem interromper processamento de outros recursos
- **FR-069**: Sistema DEVE criar √≠ndices MongoDB de forma segura, tratando erro 85 (√≠ndice existe com op√ß√µes diferentes)

**Requisitos de √çndices MongoDB (j√° implementados):**

- **FR-070**: Sistema DEVE criar √≠ndices em `occurrences` para: scientificName, iptId, ipt, canonicalName, flatScientificName, iptKingdoms, year, month, eventDate, country, stateProvince, genus, specificEpithet, kingdom, family, recordedBy, recordNumber, locality, tag, phylum, class, order
- **FR-071**: Sistema DEVE criar √≠ndices compostos em `occurrences` para: (country, stateProvince), (genus, specificEpithet), (kingdom, country), (kingdom, stateProvince), (kingdom, family)
- **FR-072**: Sistema DEVE criar √≠ndice geoespacial 2dsphere em `geoPoint` para queries geogr√°ficas
- **FR-073**: Sistema DEVE criar √≠ndice de taxonomia complexo em `occurrences`: (stateProvince, kingdom, phylum, class, order, family, genus, specificEpithet)
- **FR-074**: Sistema DEVE criar √≠ndices em `taxa` para: scientificName, kingdom, family, genus, (taxonID, kingdom), canonicalName, flatScientificName
- **FR-075**: Sistema DEVE criar √≠ndices em `ipts` para: tag, ipt

### Non-Functional Requirements

**Observability & Monitoring:**

- **NFR-001**: Sistema DEVE registrar m√©tricas operacionais b√°sicas incluindo: dura√ß√£o de cada processo de ingest√£o (por recurso IPT), dura√ß√£o de cada processo de transforma√ß√£o (taxa e occurrences separadamente), contagem de registros processados (inseridos, atualizados, com erro), taxa de erro por tipo (rede, valida√ß√£o, parsing)
- **NFR-002**: M√©tricas DEVEM ser armazenadas em cole√ß√£o MongoDB `process_metrics` com campos: process_type, resource_identifier, started_at, completed_at, duration_seconds, records_processed, records_inserted, records_updated, records_failed, error_summary
- **NFR-003**: Sistema DEVE expor endpoint `/api/health` retornando status das √∫ltimas execu√ß√µes de ingest√£o e transforma√ß√£o para monitoramento externo

### Key Entities

**Taxa (Taxonomia):**

- Representa esp√©cies, g√™neros, fam√≠lias e outras categorias taxon√¥micas
- Atributos principais: `_id`, `scientificName`, `canonicalName`, `taxonID`, `kingdom`, `phylum`, `class`, `order`, `family`, `genus`, `taxonomicStatus`
- Relacionamentos: Hierarquia taxon√¥mica (`parentNameUsageID`), sin√¥nimos (`othernames`), ocorr√™ncias associadas
- Dados agregados: Status de amea√ßa, invasoras, presen√ßa em UCs

**Occurrence (Ocorr√™ncia):**

- Representa registro de avistamento/coleta de esp√©cie em local e momento espec√≠ficos
- Atributos principais: `_id`, `occurrenceID`, `scientificName`, `canonicalName`, `taxonID`, `eventDate`, `decimalLatitude`, `decimalLongitude`, `geoPoint`, `stateProvince`, `county`, `basisOfRecord`
- Relacionamentos: Vinculada a taxon via `taxonID`, origem em reposit√≥rio IPT (`ipt`, `iptId`)
- Dados temporais: `day`, `month`, `year`, `eventDate` (timestamp)
- Dados geogr√°ficos: `continent`, `country`, `stateProvince`, `county`, `locality`, coordenadas

**IPT Resource (Recurso IPT):**

- Representa fonte de dados DwC-A em reposit√≥rio IPT
- Atributos: `nome`, `repositorio`, `kingdom`, `tag`, `url`
- 507 recursos catalogados em `occurrences.csv`

**Conservation Unit (Unidade de Conserva√ß√£o):**

- Representa √°rea protegida do cat√°logo de UCs
- Fonte: `https://ipt.jbrj.gov.br/jbrj/archive.do?r=catalogoucs`
- Agregada aos dados de taxa durante transforma√ß√£o

## Success Criteria _(mandatory)_

### Measurable Outcomes

- **SC-001**: Sistema completa ingest√£o de dados de Fauna e Flora em menos de 2 horas para conjunto completo de registros
- **SC-002**: Sistema processa todos os 507 recursos de ocorr√™ncias listados em `occurrences.csv` com taxa de sucesso superior a 95% (m√°ximo 25 recursos com falha tempor√°ria)
- **SC-003**: 100% dos registros em `taxa` possuem `_id` EXATAMENTE id√™ntico ao registro correspondente em `taxa_ipt` (valida√ß√£o por join em \_id)
- **SC-004**: 100% dos registros em `occurrences` possuem `_id` EXATAMENTE id√™ntico ao registro correspondente em `occurrences_ipt` (valida√ß√£o por join em \_id)
- **SC-004a**: Qualquer registro transformado pode ser auditado encontrando seu documento raw pelo `_id`: query `db.taxa_ipt.findOne({_id: taxa_id})` sempre retorna o documento original
- **SC-004b**: Sistema permite queries bi-direcionais: dado um `_id`, encontra-se tanto o documento raw quanto o transformado instantaneamente
- **SC-005**: 95% dos campos `canonicalName` s√£o parseados corretamente a partir de `scientificName` (valida√ß√£o manual por amostragem)
- **SC-006**: 90% das ocorr√™ncias com `scientificName` v√°lido s√£o vinculadas a `taxonID` correto da cole√ß√£o `taxa`
- **SC-007**: 100% dos registros com `eventDate` v√°lido possuem campos `day`, `month`, `year` extra√≠dos corretamente
- **SC-008**: 100% dos estados brasileiros em `stateProvince` s√£o harmonizados para formato padronizado
- **SC-009**: 95% dos munic√≠pios em `county` s√£o validados e harmonizados usando lista IBGE
- **SC-010**: APIs respondem a consultas simples em menos de 500ms para at√© 1000 resultados
- **SC-011**: Documenta√ß√£o Swagger exp√µe 100% dos endpoints de API dispon√≠veis com exemplos funcionais
- **SC-012**: Todas as p√°ginas web existentes (taxa, mapa, dashboard, tree, chat) continuam funcionando ap√≥s adapta√ß√£o
- **SC-013**: Transforma√ß√µes s√£o idempotentes: executar 2x produz exatamente o mesmo resultado que executar 1x
- **SC-014**: Processo de ingest√£o pode ser retomado ap√≥s falha sem reprocessar recursos j√° conclu√≠dos
- **SC-015**: Zero informa√ß√µes sens√≠veis (passwords, API keys, connection strings) s√£o expostas no c√≥digo-fonte p√∫blico
- **SC-016**: M√©tricas operacionais s√£o registradas para 100% dos processos de ingest√£o e transforma√ß√£o executados, incluindo dura√ß√£o, contagem de registros e taxa de erro

## Assumptions

1. **Conectividade IPT**: Assumimos que os reposit√≥rios IPT do JBRJ e SiBBr mant√™m disponibilidade superior a 95% e que indisponibilidades tempor√°rias s√£o aceit√°veis com retry posterior
2. **Formato DwC-A est√°vel**: Assumimos que o formato Darwin Core Archive permanece compat√≠vel com a vers√£o atual, com poss√≠veis novos campos sendo opcionais
3. **Schema MongoDB existente**: Assumimos que os schemas em `docs/schema-dwc2json-taxa-mongoDBJSON.json` e `docs/schema-dwc2json-ocorrencias-mongoDBJSON.json` s√£o completos e validados
4. **Infraestrutura MongoDB**: Assumimos que a inst√¢ncia MongoDB possui capacidade de armazenamento suficiente para milh√µes de registros (estimado m√≠nimo 50GB para dados brutos + transformados)
5. **Algoritmo de coletores**: Assumimos que o reposit√≥rio `https://github.com/biopinda/coletores-BO` fornece algoritmo funcional para parsing do campo `recordedBy`
6. **Lista IBGE atualizada**: Assumimos que a lista de munic√≠pios do IBGE est√° acess√≠vel em `https://www.ibge.gov.br/explica/codigos-dos-municipios.php` e permanece relativamente est√°vel
7. **C√≥digo existente reutiliz√°vel**: Assumimos que fun√ß√µes existentes em `packages/ingest/src/lib/` (processaZip, processaEml, getEml, normalization) podem ser reutilizadas na nova estrutura sem modifica√ß√µes significativas
8. **Performance aceit√°vel**: Assumimos que processamento em lote de at√© 100.000 registros por vez √© suficiente para evitar timeouts e problemas de mem√≥ria (baseado em implementa√ß√£o atual de safeInsertMany)
9. **Compatibilidade Docker**: Assumimos que a estrutura Docker atual pode ser adaptada para incluir o novo pacote `packages/transform` sem mudan√ßas arquiteturais significativas
10. **Meilisearch opcional**: Assumimos que funcionalidades dependentes de Meilisearch podem ser implementadas incrementalmente e n√£o bloqueiam o MVP

## Code Preservation Requirements

Esta se√ß√£o documenta c√≥digo e l√≥gica existentes que DEVEM ser preservados durante a refatora√ß√£o:

### Fun√ß√µes de Biblioteca a Preservar (`packages/ingest/src/lib/`)

1. **dwca.ts**:
   - `getEml(url, timeout)`: Download de metadados EML com timeout configur√°vel
   - `processaEml(eml)`: Parse de XML EML para objeto Ipt estruturado
   - `processaZip(url, isOccurrence?, batchSize?)`: Download e processamento de DwC-A com suporte a batching
   - Tipos: `DbIpt`, `Ipt`
2. **normalization.ts**:
   - `normalizeCountryName(value)`: Mapeamento de varia√ß√µes de "Brasil/Brazil" para forma can√¥nica
   - `normalizeStateName(value)`: Mapeamento completo de estados brasileiros (abrevia√ß√µes + varia√ß√µes ‚Üí nome oficial)
   - `stateMapping`: Objeto congelado com todos os mapeamentos de estados
   - `countryMapping`: Objeto congelado com mapeamentos de pa√≠ses

### L√≥gica de Processamento a Preservar

1. **Controle de Concorr√™ncia** (`ocorrencia.ts`):
   - `runWithConcurrency()`: Pool de promises com limite de execu√ß√£o simult√¢nea
   - Limit de 10 IPTs simult√¢neos durante version check
   - Timeout de 10 segundos para version checks

2. **Resili√™ncia e Error Handling**:
   - `isNetworkError()`: Detec√ß√£o de erros de rede vs erros de dados
   - `failedIpts Set`: Tracking de IPT servers offline para skip de recursos do mesmo servidor
   - Tratamento especial de HTTP 404 (recursos deletados) sem interromper processamento
   - `ordered: false` em insertMany para inser√ß√£o parcial

3. **BSON Size Management** (`ocorrencia.ts`):
   - `safeInsertMany()`: Chunking autom√°tico quando batch excede 16MB BSON limit
   - Loop de redu√ß√£o de chunk size por metade at√© sucesso
   - Redu√ß√£o de returns para √∫nico objeto de resultado

4. **Progress Tracking**:
   - Uso de `cli-progress` SingleBar para feedback visual durante inser√ß√£o
   - Incremento em duas fases (batch.length - floor/4, depois floor/4)

5. **Transforma√ß√µes de Taxonomia** (preservar de `flora.ts` e `fauna.ts`):
   - Filtro de taxonRank: apenas ['ESPECIE', 'VARIEDADE', 'FORMA', 'SUB_ESPECIE']
   - Parse de `higherClassification`: split por ';' e pegar √≠ndice [1]
   - Normaliza√ß√£o de vernacularname: lowercase com h√≠fens, capitaliza√ß√£o de language
   - Transforma√ß√£o de distribution array ‚Üí objeto estruturado (diferente para Flora vs Fauna)
   - Processamento de resourcerelationship ‚Üí othernames
   - Remo√ß√£o de vegetationType de speciesprofile.lifeForm (apenas Flora)

6. **Transforma√ß√µes de Ocorr√™ncias** (preservar de `ocorrencia.ts`):
   - Valida√ß√£o e cria√ß√£o de geoPoint apenas se coordenadas v√°lidas (lat -90 a 90, lon -180 a 180)
   - Convers√£o segura de year/month/day para n√∫meros com valida√ß√£o de ranges
   - Parse de eventDate para Date object com fallback para year/month/day
   - Cria√ß√£o de canonicalName de m√∫ltiplos campos poss√≠veis
   - Cria√ß√£o de flatScientificName (remove n√£o-alfanum√©ricos + lowercase)

7. **Index Creation**:
   - `createIndexSafely()`: Tratamento de erro 85 (√≠ndice existe com op√ß√µes diferentes)
   - Lista completa de 30+ √≠ndices para occurrences
   - √çndices compostos para otimiza√ß√£o de queries comuns
   - √çndice geoespacial 2dsphere

### Estrutura de Dados a Preservar

1. **IPT Source CSV Format** (`occurrences.csv`):
   - Colunas: nome, repositorio, kingdom, tag, url
   - Parse com PapaParse usando header:true

2. **Version Control**:
   - Compara√ß√£o de `dbVersion` vs `ipt.version` antes de reprocessar
   - Skip de processamento se vers√µes s√£o iguais
   - Upsert de IPT metadata com fields: \_id, version, tag, ipt, kingdom, set

3. **Batch Processing Pattern**:
   - Itera√ß√£o sobre batches retornados por processaZip
   - Map de cada batch antes de insertMany
   - Progress bar atualizada por batch

4. **ID Preservation Strategy (CR√çTICO)**:
   - **Taxa**: `_id` em `taxa_ipt` e `taxa` DEVE ser id√™ntico (baseado em `taxonID` do DwC-A)
   - **Occurrences**: `_id` em `occurrences_ipt` e `occurrences` DEVE ser id√™ntico (gerado de forma determin√≠stica de `occurrenceID` + `iptId`)
   - **Rastreabilidade**: Dado qualquer `_id`, deve ser poss√≠vel encontrar tanto o documento raw quanto o transformado
   - **Auditoria**: Queries como `db.taxa.findOne({_id: X})` e `db.taxa_ipt.findOne({_id: X})` retornam documentos relacionados
   - **Upsert**: Usar `_id` como chave de upsert garante idempot√™ncia e atualiza√ß√£o correta
   - **NO ObjectId gerado**: N√£o usar MongoDB ObjectId auto-gerado; sempre usar chave natural determin√≠stica

### Migration Notes

- **N√ÉO ALTERAR**: Toda a l√≥gica em `packages/ingest/src/lib/` deve ser mantida intacta
- **REUTILIZAR**: Fun√ß√µes de `flora.ts` e `fauna.ts` devem ser movidas para `packages/transform` como est√£o
- **SEPARAR**: L√≥gica de transforma√ß√£o (canonicalName, normaliza√ß√£o) deve ser extra√≠da para transform package
- **MANTER**: Estrutura de error handling, concurrency control e BSON management em ingest package

## Out of Scope

- Migra√ß√£o autom√°tica de dados das cole√ß√µes antigas (`taxa` e `occurrences` atuais) para nova estrutura
- Interface de administra√ß√£o para monitoramento de ingest√£o/transforma√ß√£o em tempo real
- Sistema de notifica√ß√µes sobre falhas em recursos IPT
- Versionamento de dados transformados (hist√≥rico de mudan√ßas)
- Valida√ß√£o taxon√¥mica profunda contra bases externas (GBIF, Catalogue of Life)
- Implementa√ß√£o de cache distribu√≠do para APIs
- Suporte a m√∫ltiplos idiomas na interface web
- Sistema de autentica√ß√£o e autoriza√ß√£o para APIs
- Implementa√ß√£o de rate limiting nas APIs
- Testes automatizados end-to-end do fluxo completo
- Otimiza√ß√£o de √≠ndices MongoDB (ser√° abordado em feature futura)
- Interface web para visualiza√ß√£o de logs de transforma√ß√£o
- Sistema de rollback autom√°tico em caso de falha na transforma√ß√£o
